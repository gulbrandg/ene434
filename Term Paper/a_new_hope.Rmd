---
title: "Projecting Norwegian Electricity Spot Prices Prior To 2030: A Scenario Analysis"
author: "Gulbrand Galaasen & Matias Kongsvik"
date: "2024-05-15"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, warning = FALSE, message = FALSE}
library(tidyverse)
library(zoo)
library(lubridate)
library(janitor)
library(hablar)
library(tsibble)
library(fpp3)
library(tseries)
library(forecast)
library(pander)
```

## Collecting data 

In this section we will detail the sources from which our data is gathered, and the methods used to load and wrangle the data. In the analysis we use data on the historical day-ahead spot prices for the five Norwegian bidding zones, load and generation in Norway, in addition to cross-border exchange and variable renewable energy generation in interconnected zones in the UK, Denmark, Germany and the Netherlands. All data is retrieved in an hourly resolution for the period between January 2018 and May 2024. Data for all countries except the UK is retrieved from ENTSO-E’s Transparency Platform ​(Transparency Platform, 2024). Due to Brexit, historical UK was no longer offered by ENTSO-E and is instead retrieved from ELEXON BSC’s Insight Solutions (Insights Solution, 2024).  

Spot prices are measured in units of Euro/MWh and retrieved for all five bidding zones: NO1, NO2, NO3, NO4 and NO5. All other data is measured in power units of MW. Data on load and generation of power are retrieved separately for all five bidding zones. Meanwhile, data on cross-border exchange and variable renewable energy generation is retrieved for interconnectors in the North Sea. Due to the scope of this paper, we have chosen not to include the interconnectors to Sweden and Finland. We acknowledge that this exclusion is a potential weakness of our analysis. 

We first establish global variables which will be used to denominate cross-border areas (bidding zones) and Norwegian bidding zones. In addition, we set the cut-off date applied to all the loaded datasets. All data collected has a common start date of 1. January 2018. 

```{r, warning=FALSE, message=FALSE}
# Where our data ends
CUT_OFF <- "2024-05-01"

# The areas/connections-to we study
areas <- c("DE", "DK", "NL", "UK")

# Bidding zones for Norwegian day-ahead electricity prices
bidding_zone <- c("NO1", "NO2", "NO3", "NO4", "NO5")
```

Datasets downloaded from ENTSO-E are only available for one year at a time. We write functions for each variable which load, wrangle and clean the 7 files for each year and bidding zone as inputs. The functions aggregate the hourly resolution to mean prices by date. The mean prices in each bidding zones in Norway is aggregated into a single mean price for each date for simplicity. Subsequent functions gather and consolidate the yearly data for each variable. Negative values for exchange signify export of Norwegian generation. Conversely, positive exchange values signify import.  

```{r, warning=FALSE, message=FALSE}
# Prices
dayAheadPrices <- function(bidding_zone, year) {
  read_csv(paste0("data/Norwegian_Day_Ahead_prices/DA_price_", bidding_zone, "_", year, ".csv"),show_col_types = FALSE) %>% 
    .[,c(1,2)] %>% 
     `colnames<-`(c("date", "price")) %>% 
    separate(date, sep="-", into=c("date", NULL)) %>% 
    mutate(date = as.Date(date, "%d.%m.%Y %H:%M")) %>% 
    mutate(price = as.double(price),
           bidding_zone = bidding_zone) %>%
    group_by(date) %>%
    filter(date < as.Date(CUT_OFF)) %>%
    summarise(price = mean(price, na.rm = TRUE), bidding_zone = unique(bidding_zone))
}

gather_dayAheadPrices <- function(bidding_zone) {
  map2(rep(bidding_zone, 7), c("2018":"2024"), dayAheadPrices) %>% 
    bind_rows()
}


# Exchange
cross_border_flow <- function(area, year) {
  read_csv(paste0("data/exchange/", area, "_", year, ".csv"), show_col_types = FALSE) %>% 
    .[,c(1,2,3)] %>% 
     `colnames<-`(c("date", "import", "export")) %>% 
    separate(date, sep="-", into=c("date", NULL)) %>% 
    mutate(import = as.double(import, na.rm = TRUE),
           export = as.double(export, na.rm = TRUE)) %>% 
    mutate(date = as.Date(date, "%d.%m.%Y %H:%M")) %>% 
    group_by(date) %>%
    summarize(exchange = mean(import, na.rm = TRUE) - mean(export, na.rm = TRUE)) %>% 
    mutate(area = area) %>% 
    filter(date < as.Date(CUT_OFF))
}

gather_cross_flow <- function(area) {
  map2(rep(area, 7), c("2018":"2024"), cross_border_flow) %>% 
    bind_rows()
}


# Consumption
gather_load <- function(area, year) {
  read_csv(paste0("data/load_", area, "/load_", area, "_", year, ".csv")) %>% 
    .[,c(1,3)] %>% 
    `colnames<-`(c("date", "load")) %>% 
    drop_na() %>% 
    separate(date, sep="-", into=c("date", NULL)) %>% 
    mutate(date = as.Date(date, "%d.%m.%Y %H:%M")) %>% 
    mutate(load = as.double(load)) %>%
    group_by(date) %>% 
    summarize(load = mean(load)) %>% 
    filter(date < as.Date(CUT_OFF))
}

gather_load_area <- function(area) {
  map2(rep(area, 7), c("2018":"2024"), gather_load) %>% 
    bind_rows() %>%  
    mutate(area = area)
}

# Generation
gather_generation <- function(area, year) {
  if (area == "NO") {
    read_csv(paste0("data/generation/gen_", area, "/gen_", area, "_", year, ".csv"), na = c("n/e", "N/A", "-")) %>% 
      .[,2:23] %>% 
      mutate(gen = rowSums(.[,2:22], na.rm = TRUE)) %>% 
      select(MTU, gen) %>% 
      rename(date = MTU) %>% 
      drop_na() %>% 
      separate(date, sep="-", into=c("date", NULL)) %>%
      mutate(date = as.Date(date, "%d.%m.%Y %H:%M")) %>% 
      group_by(date) %>% 
      summarize(gen = mean(gen)) %>% 
      filter(date < as.Date(CUT_OFF))
      
  } else {
    read_csv(paste0("data/generation/gen_", area, "/gen_", area, "_", year, ".csv")) %>% 
      .[,c(2,20,22,23)] %>% 
      `colnames<-`(c("date", "sol", "wnd_off", "wnd_on")) %>% 
      drop_na() %>% 
      separate(date, sep="-", into=c("date", NULL)) %>% 
      mutate(vre = as.double(sol) + as.double(wnd_off) + as.double(wnd_on)) %>%
      mutate(date = as.Date(date, "%d.%m.%Y %H:%M")) %>% 
      group_by(date) %>% 
      summarize(vre = mean(vre)) %>% 
      filter(date < as.Date(CUT_OFF))
  }
}

# Generation
gather_generation_area <- function(area) {
  # Special case for UK data as these are not present in Etsoe because of Brexit
  if (area == "UK") {
    read_csv(paste0("data/generation/gen_", area, "/gen_", area, ".csv")) %>% 
      .[,c(3,6,7)] %>% 
      `colnames<-`(c("date", "type", "vre")) %>%
      filter(type %in% c("WIND")) %>% 
      mutate(vre = as.double(vre)) %>% 
      mutate(date = as.Date(with_tz(date, tzone = "Europe/Oslo"), tz = "Europe/Oslo")) %>% 
      group_by(date) %>%
      summarize(vre = mean(vre, na.rm = TRUE)) %>% 
      arrange(date) %>% 
      filter(date < as.Date(CUT_OFF)) %>% 
      mutate(area = area)
      
  } else {
    map2(rep(area, 7), c("2018":"2024"), gather_generation) %>% 
      bind_rows() %>%  
      mutate(area = area) 
  }
}
```

Data frames for each variable are loaded into memory and subsequently consolidated into the data frame df. There exist some NaN values in exchange due to maintenance which we set to 0. 

```{r, warning=FALSE, message=FALSE}
# Load data into memory

# Prices
price <- map(bidding_zone, gather_dayAheadPrices) %>%
  bind_rows() %>% 
  group_by(date) %>% 
  summarise(price = mean(price, na.rm = TRUE))

# Exchange
exchange <- map(areas, gather_cross_flow) %>%
  bind_rows()

# Consumption
load_NO <- gather_load_area("NO")

# Generation
gen_NO <- gather_generation_area("NO")

# Variable renewable production
vre <- map(areas, gather_generation_area) %>% 
  bind_rows()
```

```{r, warning=FALSE, message=FALSE}
df <- exchange %>% 
  inner_join(., vre, by = c("date", "area")) %>% 
  inner_join(., gen_NO[,c(1,2)], by = c("date")) %>% 
  inner_join(., load_NO[,c(1,2)], by = c("date")) %>% 
  inner_join(., price[,c(1,2)], by = c("date"))

is.nan.data.frame <- function(x)
do.call(cbind, lapply(x, is.nan))
df[is.nan(df)] <- 0
```

## Stationarity testing

Before we do anything else we want to ensure that the data we will later use is stationary. This is done by conducting an Augmented Dickey-Fuller (adf) test.

```{r, warning=FALSE, message=FALSE}
df_adf_test <- df %>% 
  group_by(date) %>% 
  summarise(price = first(price),
            gen = first(gen),
            load = first(load))

ex_DE <- df %>% filter(area == "DE")
ex_DK <- df %>% filter(area == "DK")
ex_NL <- df %>% filter(area == "NL")
ex_UK <- df %>% filter(area == "UK")
  

adf.test(df_adf_test$price) # stationary
adf.test(df_adf_test$gen) # stationary
adf.test(df_adf_test$load) # not stationary

adf.test(ex_DE$exchange) # stationary
adf.test(ex_DK$exchange) # stationary
adf.test(ex_NL$exchange) # stationary
adf.test(ex_UK$exchange) # stationary
```
We find that all data is stationary within a statistically significant level, except the load (consumption) data, which is likely because of its seasonality. This will be addressed by introducing measures to account for seasonality in all forecasting models where the consumption is present as a variable.

## Descriptive analysis

To create a price-model using exchange, load and vre as explanatory variables, we need to synthesize future data for these variables. Additionally, the model must account for the maximum transmission capacity of each interconnector, ensuring that exchange cannot exceed the physical constraints of transmission.  

Descriptive analysis of the data will provide insight into the drivers for each variable, enabling us to synthesize scenarios of future data to be used in our final price-model. Below is the code for the scatterplots with linear regression lines for the explanatory variables, facet wrapped by area. 

The scatterplots will enable us to better understand how the correlation between one explanatory variable and the other for each area.  

## Descriptive analysis of price

Our overall goal is to project price, and thus we need to understand what drives price. 

```{r, warning = FALSE, message = FALSE}
price_df <-
  df %>% 
  group_by(date) %>% 
  summarise(price = first(price),
            gen = first(gen),
            load = first(load),
            exchange = sum(exchange)) %>% 
  pivot_longer(cols = c("exchange", "gen", "load"))

price_df %>% 
  filter(value != 0) %>% 
  ggplot(aes(x = value, y = price, color = date)) +
  geom_point(cex = 0.7) +
  facet_wrap(~ name, scales = 'free_x')+
  geom_smooth(method = "loess", color = "red") +
  labs(title = "Price drivers", x = "value", y = "Price in €/MWh", color = "Date") + 
  theme(legend.position = "bottom", plot.title = element_text(hjust = 0.5))

```

Plotting exchange, generation and consumption to explain price, we see that there are different and complex relations. First of all data points seem to form clusters based on their date, which makes sense as different periods since 2018 have had different price levels, with some periods being abnormally high. 

For exchange it is difficult to pinpoint any exact relation to price. High export (negative exchange) and import (positive exchange) seems to give higher prices than small export and small import values. Additionally, different time periods for when the exchange occurred seems to display different relations to price. The difficulty of determining this relationship calls for more complex methods, which we later will implement.                                          For generation, low and high values seems to be correlated positively with higher prices. This makes intuitively sense, as abnormally low generation likely indicates lack of production capacity which is needed, and abnormally high generation indicates that higher merit order of production types are used, which has a higher marginal production cost.                           For load, there seems to exist a positive linear trend, which makes sense as lower consumption requires less production, and the lowest marginal cost production types and facilities are used. When the consumption is higher the opposite is true, and the price is therefore higher. Interestingly, there also seems to exist a trend in some time periods similar to that of generation, where lower and higher values correlates with a higher price. 

Based on the analysis above, we can conclude that a more complex model than linear regression is needed to project long term future prices. If we want to do this we would need to synthesize the variables discussed We start by synthesizing exchange by creating forecasting models for each connected overseas area. Before this we conduct a similar analysis where we identify potential drivers for exchange.   

## Descriptive analysis of exchange

```{r, warning = FALSE, message = FALSE}
Facet_gen <- df %>% 
  select(date, exchange, area, gen) %>% 
  filter(exchange != 0) %>% 
  ggplot(aes(x = gen, y = exchange, color = date)) +
  geom_point(cex = 0.7) +
  facet_wrap(~ area, scales = 'free_y')+
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Exchange explained by Generation", x = "Generation", y = "Exchange", color = "Date") + 
  theme(legend.position = "bottom", plot.title = element_text(hjust = 0.5))

Facet_vre <- df %>% 
  select(date, exchange, area, vre) %>% 
  filter(exchange != 0) %>% 
  ggplot(aes(x = vre, y = exchange, color = date)) +
  geom_point(cex = 0.7) +
  facet_wrap(~ area, scales = 'free')+
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Exchange explained by VRE", x = "VRE", y = "Exchange", color = "Date") + 
  theme(legend.position = "bottom", plot.title = element_text(hjust = 0.5))

Facet_load <- df %>% 
  select(date, exchange, area, load) %>% 
  filter(exchange != 0) %>% 
  ggplot(aes(x = load, y = exchange, color = date)) +
  geom_point(cex = 0.7) +
  facet_wrap(~ area, scales = 'free')+
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Exchange explained by Consumption", x = "Consumption", y = "Exchange", color = "Date") + 
  theme(legend.position = "bottom", plot.title = element_text(hjust = 0.5))
```

```{r, warning=FALSE, message=FALSE}
Facet_gen
```

The plot above indicates a negative correlation between exchange and generation in NO across all areas, meaning an increase in export is correlated with an increase in NO generation. The incline of the regression lines suggests the degree of correlation is similar in size(forholdet?). NO appears to be a net exporter to all areas, although this is less evident for DK.  Norwegian import when domestic generation is low seems to be more prominent for DE and DK, than NL and UK. This might suggest that Norwegian power producers are more capable of adjusting generation to power imported from DE and DK, or that power generation in DK is more prevalent during periods of low power generation in Norway, possibly due to high water values.  
```{r, warning=FALSE, message=FALSE}
Facet_vre
```

The plot above indicates a varying degree of positive correlation between exchange and variable renewable energy production in border areas, showing a trend of import when vre is available. However, this correlation is negligible for the UK. Conversely, DK and DE appear to have a linear relationship between exchange and vre. This might suggest that vre production is a driver for exchange between NO and these areas. This does not seem to be the case for UK where there is no incline.  

```{r}
Facet_load
```

The plot above shows different correlations between exchange and load for bordering areas. Exchange to DE, DK and NL are positively correlated with NO load, while this relationship is opposite for the UK, exchange being is negatively correlated with load. The former suggest that with lower power consumption in Norway, power export increases. The latter might suggest that an increase in consumption of electricity in Norway relates to more export to the UK, however, there are some outliers to the right of the plot which might explain the slope of the regression line.  

```{r, warning=FALSE, message=FALSE}
get_coeff_gen <- function(a) {
  df %>% 
    select(date, exchange, area, gen) %>% 
    filter(exchange != 0) %>% 
    filter(area == a) %>% 
    lm(data = ., formula = exchange ~ gen) %>% 
    summary(.) %>% 
    .$coefficients %>% 
    as_tibble() %>% 
    .[2,c("Estimate", "Pr(>|t|)")] %>%
    `colnames<-`(c("coeff", "p_value")) %>% 
    mutate(p_value = ifelse(p_value > 0.1, "-", 
                     ifelse(p_value > 0.05, "*", 
                     ifelse(p_value > 0.01, "**", "***")))) %>% 
    mutate(coeff = paste0(round(coeff, 3), " ", p_value)) %>% 
    .$coeff
}

get_coeff_vre <- function(a) {
  df %>% 
    select(date, exchange, area, vre) %>% 
    filter(exchange != 0) %>% 
    filter(area == a) %>% 
    lm(data = ., formula = exchange ~ vre) %>% 
    summary(.) %>% 
    .$coefficients %>% 
    as_tibble() %>% 
    .[2,c("Estimate", "Pr(>|t|)")] %>%
    `colnames<-`(c("coeff", "p_value")) %>% 
    mutate(p_value = ifelse(p_value > 0.1, "-", 
                     ifelse(p_value > 0.05, "*", 
                     ifelse(p_value > 0.01, "**", "***")))) %>% 
    mutate(coeff = paste0(round(coeff, 3), " ", p_value)) %>% 
    .$coeff
}

get_coeff_load <- function(a) {
  df %>% 
    select(date, exchange, area, load) %>% 
    filter(exchange != 0) %>% 
    filter(area == a) %>% 
    lm(data = ., formula = exchange ~ load) %>% 
    summary(.) %>% 
    .$coefficients %>% 
    as_tibble() %>% 
    .[2,c("Estimate", "Pr(>|t|)")] %>%
    `colnames<-`(c("coeff", "p_value")) %>% 
    mutate(p_value = ifelse(p_value > 0.1, "-", 
                     ifelse(p_value > 0.05, "*", 
                     ifelse(p_value > 0.01, "**", "***")))) %>% 
    mutate(coeff = paste0(round(coeff, 3), " ", p_value)) %>% 
    .$coeff
}

tibble(area = areas) %>% 
  mutate(gen = unlist(map(areas, get_coeff_gen)),
         vre = unlist(map(areas, get_coeff_vre)),
         load = unlist(map(areas, get_coeff_load))) %>% 
  pander()
```
In the above the table the numerical results for the regression are summarized. We find that our intuition was correct, where ...

## Forecast exchange

Next, we want to forecast exchange between Norway and countries that are connected with an oversea cable. These include Germany (DE), Denmark (DK), the Netherlands (NL) and United Kingdom (UK). We first define capacity parameters on all cables using the historical maximum and minimum we find in the data. These coincide with capacities that are found online (source). Secondly, we define a date range which sets the timeline for the forecast. Lastly, we need to define how the increase in consumption and variable renewable energy will happen. Here we use a simple linear increase in both, such that the level at any given time will be the original level multiplied with the target level and percentage of the time elapsed to 2030.  To give an example for the variable renewable energy production, the first date (2024-05-01) in our forecast will be the level multiplied by 1.  The median date (2027-02-02) will be the level multiplied by 1.25, and the last date (2029-12-31) will be the level multiplied with 1.5. Thus, we model a 50% total increase in variable renewable energy production over the given forecast horizon.  


```{r, warning=FALSE, message=FALSE}
cap <- tibble(area = c("DE", "DK", "NL", "UK"),
              import_cap = c(1425, 1639, 730, 1330),
              export_cap = c(-1407, -1658, -706, -1450),
              from_date = c("2021-01-01", "2021-01-01", "2023-01-01", "2022-01-01"))

DATE_RANGE <- seq(as.Date(CUT_OFF), as.Date("2029-12-31"), by = "day")

N_DAYS <- length(DATE_RANGE)

load_inc <- (seq(1:N_DAYS) / N_DAYS * 0.1) + 1
vre_inc <- (seq(1:N_DAYS) / N_DAYS * 0.5) + 1

```

Since we want to forecast the exchange with variable renewable energy production and consumption, we need to synthesis data for these variables in the forecast horizon.   

We start by synthesizing variable renewable production. This is done by taking data from 2023 and creating a pool of values for each month and area. Then for a single date, a future value is drawn from this pool given a month and area, and is then multiplied by a random factor [0.9, 1.1] to essentially simulate the uncertainty of wind and solar for a given day. Doing it this way the idea is to keep monthly trends for future values, while also introducing uncertainty that is present in such a variable.  

```{r, warning=FALSE, message=FALSE}
# Synthesize vre
vre_area_month <-
  df %>% 
  filter(date >= as.Date("2023-01-01")) %>% 
  filter(date < as.Date("2024-01-01")) %>% 
  mutate(month = month(date)) %>% 
  select(month, area, vre)

draw_vre <- function(a, m) {
  vre_area_month %>%
    filter(area == a) %>% 
    filter(month == m) %>% 
    .$vre %>% 
    sample(1, replace = TRUE) * runif(1, min = 0.9, max = 1.1)
} 
```

We also need to synthesize the future consumption. We can do this using the same method as for the variable renewable energy production, but the seasonality would not be kept in a good way. Therefore, we instead synthesize the data by creating an ARIMA model with fourier terms to create more feasible data. Here a fourier term is added for yearly and weekly seasonality. The model also includes an AR(3) and MA(1), these parameters were found by looking at the residual plot and studying the AICc.    

```{r, warning=FALSE, message=FALSE}
load_data <- df %>% 
  group_by(date) %>% 
  summarise(load = first(load)) %>% 
  tsibble(index = date) 

load_model <- 
  load_data %>% 
  model(mod = ARIMA(load ~ pdq(3,0,1) + PDQ(0,0,0) +
                      fourier(period = 365, K = 10) +
                      fourier(period = 7, K = 3)
                    )
  )

load_model %>% gg_tsresiduals()

future_load <-
  load_model %>% 
  forecast(h = N_DAYS) %>% 
  rename(steady_load = .mean) %>% 
  mutate(increasing_load = steady_load * load_inc) %>% 
  select(date, steady_load, increasing_load)

future_load %>% 
  ggplot() +
  geom_line(aes(x = date, y = steady_load, color = "steady load")) + 
  geom_line(aes(x = date, y = increasing_load, color = "increasing load")) +
  labs(x = "Date", y = "Load", title = "Increasing and steady load to 2030")

```

The final model still has some residual peaks on the 21st, 23rd and 25th lag, but the residual histogram looks normally distributed. Another point here is that we do not necessarily want the model to exactly fit the data, but rather we want the forecast to look feasible. From the forecasted plot, we can see that this is indeed the case, and we accept the model.   

Next, we define a function which creates a dataset for each exchange area. This dataset will include the historical data on the variable renewable production and consumption, and the scenarios for future variable renewable production and consumption, namely for steady and increasing states.

```{r, warning=FALSE, message=FALSE}

create_dataset_area <- function(a) {
  from_date <- cap %>% 
    filter(area == a) %>% 
    .$from_date
  
  old_df <-
    df %>% 
    filter(area == a) %>% 
    filter(date >= as.Date(from_date)) %>% 
    select(date, area, exchange, vre, load) %>% 
    mutate(increasing_vre = NA,
           increasing_load = NA)
  
  new_df <- 
    tibble(date = DATE_RANGE,
           area = a,
           exchange = NA,
           vre = unlist(map2(a, month(date), draw_vre)),
           increasing_vre = unlist(map2(a, month(date), draw_vre)) * vre_inc,
           load = future_load$steady_load,
           increasing_load = future_load$increasing_load)

  return(
    rbind(old_df, new_df) %>% 
      tsibble(index = date) 
  )
} 

```


```{r, warning=FALSE, message=FALSE}

forecast_exchange <- function(a) {
  print(paste0("Exchange model for area: ", a))
  
  import_cap <- cap %>% 
    filter(area == a) %>% 
    .$import_cap
  
  export_cap <- cap %>% 
    filter(area == a) %>% 
    .$export_cap
  
  data <- create_dataset_area(a)
  
  data_fit <- data %>% 
    filter(date < as.Date(CUT_OFF))
  
  data_pred <- data %>% 
    filter(date >= as.Date(CUT_OFF))
  
  model <- 
    data_fit %>% 
    fill_gaps() %>%
    model(mod = ARIMA(exchange ~ vre + load + fourier(period = 7, K = 3)))
  
  print(model$mod)
  
  model %>% 
    gg_tsresiduals() %>% 
    print()
  
  # Scenario 1: steady vre and steady load
  pred1 <- 
    model %>% 
    forecast(., new_data = data_pred) %>% 
    mutate(s1 = unlist(map2(.mean, rep(import_cap, N_DAYS), min))) %>% 
    mutate(s1 = unlist(map2(s1, rep(export_cap, N_DAYS), max))) 
  
  # Scenario 2: Increasing vre and steady load
  pred2 <- 
    model %>% 
    forecast(., new_data = (data_pred %>% mutate(vre = increasing_vre))) %>% 
    mutate(f = unlist(map2(.mean, rep(import_cap, N_DAYS), min))) %>% 
    mutate(f = unlist(map2(f, rep(export_cap, N_DAYS), max)))

  # Scenario 3: Steady vre and increasing load
  pred3 <- 
    model %>% 
    forecast(., new_data = (data_pred %>% mutate(load = increasing_load))) %>% 
    mutate(f = unlist(map2(.mean, rep(import_cap, N_DAYS), min))) %>% 
    mutate(f = unlist(map2(f, rep(export_cap, N_DAYS), max)))

  # Scenario 4: Increasing vre and increasing load
  pred4 <- 
    model %>% 
    forecast(., new_data = (data_pred %>% mutate(vre = increasing_vre, load = increasing_load))) %>% 
    mutate(f = unlist(map2(.mean, rep(import_cap, N_DAYS), min))) %>% 
    mutate(f = unlist(map2(f, rep(export_cap, N_DAYS), max)))
  
  pred <- pred1 %>% 
    mutate(s2 = pred2$f,
           s3 = pred3$f,
           s4 = pred4$f)

  return(pred %>% 
           as_tibble() %>% 
           select(date, area, s1, s2, s3, s4))
}

set.seed(434) # Set seed for reproducibility
exchange_forecast <- map(areas, forecast_exchange) %>% 
  bind_rows() %>% 
  group_by(date) %>% 
  summarise(s1 = sum(s1),
            s2 = sum(s2),
            s3 = sum(s3),
            s4 = sum(s4))
```
Here, one model is created for each area, as the relation between exchange and variable renewable energy production differs from area to area. The DE-model looks quite good with normally distributed residuals, but has some significant spikes. The DK-model has no significant spikes 

## Price projection

After synthesizing exchange and consumption data we can create our price model. The model will be fitted on historical exchange and consumption, and project the Norwegian electricity price for each defined scenario. The model will only be fitted on data from 2022-01-01 until 2024-05-01. This is because we do not want to include the unprecedented prices of 2021, as we do not believe that these represent the future level of Norwegian electricity prices.

First, we create fitting data with the historical values of the price, exchange and consumption. Then we create a data frame containing exchange and consumption values for all scenarios. 

```{r, warning=FALSE, message=FALSE}
pdf <- df %>% 
  group_by(date) %>% 
  summarise(price = first(price),
            exchange = sum(exchange),
            load = first(load)) %>% 
  filter(date >= as.Date("2022-01-01")) %>% 
  tsibble(index = date)
  
future <- 
  exchange_forecast %>% 
  mutate(steady_load = future_load$steady_load,
         increasing_load = future_load$increasing_load) %>% 
  tsibble(index = date)
```

Next we define our model using the same principles as before. We want to have as few spikes in the ACF-plot as possible, while the residuals should be normally distributed. We account for seasonality by adding fourirer terms. After some testing we find a model with MA(3), and three different fourier terms.    

```{r, warning=FALSE, message=FALSE}
model <- 
  pdf %>% 
  fill_gaps() %>%
  model(mod = ARIMA(price ~ exchange + load + pdq(0,1,3) + PDQ(0,0,0) +
                      fourier(period = 6, K = 2) +
                      fourier(period = 7, K = 1) +
                      fourier(period = 9, K = 4)))

model %>% 
  report()

model %>% 
  gg_tsresiduals()
```
The residuals of the model looks sufficiently normally distributed, but there is one spike at lag 13 which we were not able to adjust for. Price data is notoriously difficult to create good models on, as there are many variables and events that can affect it. Looking at the residuals it looks like the model finds it difficult to fit values in late 2022, this can be explained by abnormally high prices in this period. Since we want to project a more general price level over a longer time it is not critical that our model can explain these price spikes. Thus, we accept the model.  

Next we create a forecast for each scenario with the corresponding data.

```{r, warning=FALSE, message=FALSE}
# Scenario 1
print("Scenario 1: Steady vre and steady load")
pred1 <- 
  model %>% 
  forecast(., new_data = (future %>% mutate(exchange = s1, load = steady_load)))

pred1 %>% 
  autoplot(pdf) +
  labs(title = "Projection for Scenario 1", x = "Date", y = "Price in €/MWh")

# Scenario 2
print("Scenario 2: Increasing vre and steady load")
pred2 <- 
  model %>% 
  forecast(., new_data = (future %>% mutate(exchange = s2, load = steady_load))) 

pred2 %>% 
  autoplot(pdf) +
  labs(title = "Projection for Scenario 2", x = "Date", y = "Price in €/MWh")

# Scenario 3
print("Scenario 3: Steady vre and increasing load")
pred3 <- 
  model %>% 
  forecast(., new_data = (future %>% mutate(exchange = s3, load = increasing_load))) 

pred3 %>% 
  autoplot(pdf) +
  labs(title = "Projection for Scenario 3", x = "Date", y = "Price in €/MWh")

# Scenario 4
print("Scenario 4: Increasing vre and increasing load")
pred4 <- 
  model %>% 
  forecast(., new_data = (future %>% mutate(exchange = s4, load = increasing_load))) 

pred4 %>% 
  autoplot(pdf) +
  labs(title = "Projection for Scenario 4", x = "Date", y = "Price in €/MWh")

```
Looking at the projections for the different scenarios they all share a similar seasonality, where the prices are lower in the summer months and higher during the winter months. As time elapses, the uncertainty of the projection increases, an expected result due to limited explanatory power of the model. This is also emphasized by the residual plot above. It should also be noted that the model does not differentiate between negative and positive prices, and finds each as likely. Domain knowledge on electricity markets does not support this notion. Negative prices are a relatively rare occurrence and is very unlikely to dip far below zero. However, our goal is to compare general price levels of different scenarios, rather than trying to giving an exact forecast, and this model will in this regard be suitable. 

```{r, warning=FALSE, message=FALSE}
tibble(Scenario = c("Scenario 1", "Scenario 2", "Scenario 3", "Scenario 4"),
       vre = c("Steady", "Increasing", "Steady", "Increasing"),
       load = c("Steady", "Steady", "Increasing", "Increasing"),
       Mean = c(paste0(round(mean(pred1$.mean), 2), " €/MWh"), 
                paste0(round(mean(pred2$.mean), 2), " €/MWh"), 
                paste0(round(mean(pred3$.mean), 2), " €/MWh"), 
                paste0(round(mean(pred4$.mean), 2), " €/MWh")),
       "% diff mean" = 
         c(
           paste0(round(-(mean(pred1$.mean) - mean(pred1$.mean)) / mean(pred1$.mean) * 100, 2), "%"), 
           paste0(round(-(mean(pred1$.mean) - mean(pred2$.mean)) / mean(pred1$.mean) * 100, 2), "%"),
           paste0(round(-(mean(pred1$.mean) - mean(pred3$.mean)) / mean(pred1$.mean) * 100, 2), "%"), 
           paste0(round(-(mean(pred1$.mean) - mean(pred4$.mean)) / mean(pred1$.mean) * 100, 2), "%")),
       std = c(sqrt(var(pred1$.mean)), 
               sqrt(var(pred2$.mean)), 
               sqrt(var(pred3$.mean)), 
               sqrt(var(pred4$.mean)))) %>% 
  pander()
```
In the table above the calculated mean and standard deviation for each scenario are presented. We compare each scenario with Scenario 1 to examine how an increase in variable renewable production and an increase in consumption affects the spot price level prior to 2030. 

Scenario 2, where an 50% increase in variable renewable energy production and steady consumption is modeled, has a 6.49% lower price level than the base scenario. This results coincides with our intuition. If there is a higher production in the overseas countries, this production will partly go to Norway, shifting the supply curve positively, thus reducing the price level. The standard deviation, which we interpret as price volatility, is somewhat lower. This is not what we would expect, as an increase in variable renewable energy would induce higher volatility in the overseas production, which again would transfer to the supply curve in Norway. This might be because of the bottlenecks of transmission, or simply that the data is too aggregated on a daily level, and that we would actually find such a result in an hourly resolution. Our rather simplified modelling assumptions might also be the cause of this. 

Scenario 3, where steady variable renewable energy production and an 10% increasing consumption is modeled, there is a 10.07% increase in the price level compared to Scenario 1. This aligns with our intuition, where a higher consumption positively shifts the demand curve, resulting in higher prices. Here the standard deviation is also higher than Scenario 1, which also makes sense as the positive shift in demand generally increases the price. 

Scenario 4, where an 50% increase in variable renewable energy production and an 10% increasing consumption is modeled, gives an 3.82% increase in the price level compared to Scenario 1. After examining Scenario 2 and 3 this seems reasonable, and indicates that the effect of an increase of 10% in consumption is larger than the effect of an increase of 50% in variable renewable energy. The standard deviation is lower than Scenario 3 but still higher than Scenario 1, which aligns with what we found in the comparison of means. 

Overall it seems like the effect of an increased consumption is larger than the effect of an increased variable renewable energy production in overseas countries. This is an interesting finding, especially considering that the increase in variable renewable energy production was five-fold compared to the increase in consumption. A likely reason for this is of course the bottlenecks introduced by the oversea cable connections in the system. This is a known reason for price difference between zones, which we also have taken into account into our modelling approach. Therefore, our analysis indicates that the capacities of the connections should be expanded along with increasing variable renewable production in overseas countries, if the goal is to reduce the spot price level of electricity in Norway.
