---
title: "Untitled"
author: "Matias Kongsvik"
date: "2024-04-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(zoo)
library(lubridate)
library(janitor)
library(hablar)
library(tsibble)
library(fpp3)

```

Convert one data set to a time series tibble

```{r}

# Set work directory
setwd("/Users/matiaskongsvik/Documents/NHH VaÌŠr 24/ENE434")

# Load data and clean column names
NO1_gen_type_2015<- read_csv("Term Paper/NO1_generation_per_type/Actual Generation per Production Type_201501010000-201601010000.csv") %>% 
  janitor::clean_names()

# Clean time stamp data
NO1_gen_type_2015 <- NO1_gen_type_2015 %>%
  separate(mtu, sep="-", into=c("period", "end")) %>%
  mutate(end = str_remove(end, "\\s*\\(CET/CEST\\)"))

# Format time stamp data
NO1_gen_type_2015 <- NO1_gen_type_2015 %>% mutate(
  period = as.POSIXct(period, format="%d.%m.%Y %H:%M", tz = "CET"),
  end = as.POSIXct(end, format="%d.%m.%Y %H:%M", tz = "CET"),
  year = year(period),
  month = month(period)
)

# Remove NA values
NO1_gen_type_2015 <- NO1_gen_type_2015 %>% 
  filter(!is.na(period))

# Check for duplicates
duplicates(NO1_gen_type_2015, index = "period")

# Remove second entry duplicate
NO1_gen_type_2015 = NO1_gen_type_2015 %>% 
  filter(!c(period == "2015-10-25 02:00:00" & hydro_water_reservoir_actual_aggregated_mw == 1154))

# There are only 8759 observations, which means that there are missing values.
# We need to generate a complete sequence of dates and fill in the missing values by carrying forward

# Generate a complete sequence of dates
complete_dates <- data_frame(
  period = seq(from = as.POSIXct("2015-01-01 00:00:00", tz = "CET"), 
               to = as.POSIXct("2015-12-31 23:00:00", tz = "CET"), 
               by = "hour")
)

# Merge to find missing dates and fill missing values by carrying forward
NO1_gen_type_2015 <- complete_dates %>%
  left_join(NO1_gen_type_2015, by = "period") %>%
  fill(names(NO1_gen_type_2015), .direction = "down")

# Check if there are still any NAs, potentially from the first few hours if they were missing
still_missing15 <- sum(is.na(NO1_gen_type_2015))
print(paste("Still missing after fill:", still_missing15))

#save the completed dataset
#write_csv(NO1_gen_type_2015_complete, "NO1_gen_type_2015_complete.csv")

# Covert to time series tibble
NO1_gen_type_2015 <- NO1_gen_type_2015 %>% 
  as_tsibble(index = period)
```

Function to automate the process above
```{r}
# Automate the process above in a function which takes the file path for datasets as an argument

process_generation_data <- function(file_path) {
  # Load data and clean column names
  generation_data <- read_csv(file_path) %>% 
    clean_names()
  
  # Clean time stamp data
  generation_data <- generation_data %>%
    separate(mtu, sep="-", into=c("period", "end")) %>%
    mutate(end = str_remove(end, "\\s*\\(CET/CEST\\)"))
  
  # Format time stamp data
  generation_data <- generation_data %>%
    mutate(period = as.POSIXct(period, format="%d.%m.%Y %H:%M", tz = "CET"),
           end = as.POSIXct(end, format="%d.%m.%Y %H:%M", tz = "CET"),
           year = year(period),
           month = month(period)) %>%
    filter(!is.na(period))
  
  # Remove duplicates, preferentially keep rows with more complete data
  generation_data <- generation_data %>%
    arrange(desc(is.na(hydro_water_reservoir_actual_aggregated_mw))) %>%  # Prioritize by less NAs in a key column if desired
    group_by(period) %>%
    filter(row_number() == 1) %>%  # Keep the first occurrence
    ungroup()
  
  # Create a sequence of complete dates for the given year
  year_used <- unique(year(generation_data$period))
  start_date <- as.POSIXct(paste(year_used, "-01-01 00:00", sep=""), tz = "CET")
  end_date <- as.POSIXct(paste(year_used, "-12-31 23:00", sep=""), tz = "CET")
  
  complete_dates <- data_frame(
    period = seq(from = start_date, to = end_date, by = "hour")
  )
  
  # Merge to find missing dates and fill missing values by carrying forward
  generation_data <- complete_dates %>%
    left_join(generation_data, by = "period") %>%
    fill(names(generation_data), .direction = "down")
  
  # Check for missing values
  still_missing <- sum(is.na(generation_data))
  print(paste("Still missing after fill:", still_missing))
  
  # Create a variable name based on the year
  variable_name <- paste("NO1_gen_type_", year_used, sep="")
  assign(variable_name, generation_data, envir = .GlobalEnv)
  
  return(generation_data)
}

```

Finished function for loading and cleaning all files combined to one
```{r, warning = FALSE}
process_generation_data_folder <- function(folder_path) {
  file_list <- list.files(path = folder_path, pattern = "\\.csv$", full.names = TRUE)
  all_data <- lapply(file_list, function(file_path) {
    generation_data <- read_csv(file_path, show_col_types = FALSE) %>% 
      clean_names() %>%
      hablar::retype() %>%  # Attempt to auto-detect and set correct types
      separate(mtu, sep="-", into=c("period", "end")) %>%
      mutate(end = str_remove(end, "\\s*\\(CET/CEST\\)"),
             period = as.POSIXct(period, format="%d.%m.%Y %H:%M", tz = "CET"),
             end = as.POSIXct(end, format="%d.%m.%Y %H:%M", tz = "CET"),
             date = lead(as.Date(period), 1)) %>%  # Convert period to Date for summarizing and lead to match posixct
      filter(!is.na(period)) %>%
      arrange(desc(is.na(hydro_water_reservoir_actual_aggregated_mw))) %>%
      group_by(period) %>%
      filter(row_number() == 1) %>%
      ungroup()

    # Enforce double type for all columns from the 4th onward
    column_indices <- 4:(ncol(generation_data)-1)  # Indices of columns to convert
    generation_data <- generation_data %>%
      mutate(across(.cols = column_indices, .fns = ~as.numeric(.x)))

    # Complete date sequence for the given year
    year_used <- unique(year(generation_data$period))
    start_date <- as.POSIXct(paste(year_used, "-01-01 00:00", sep=""), tz = "CET")
    end_date <- as.POSIXct(paste(year_used, "-12-31 23:00", sep=""), tz = "CET")
    complete_dates <- tibble(period = seq(from = start_date, to = end_date, by = "hour"))

    # Merge and fill
    generation_data <- complete_dates %>%
      left_join(generation_data, by = "period") %>%
      fill(names(generation_data), .direction = "down") %>%
      as_tsibble(index = period)

    return(generation_data)
  })

  return(all_data)
}

# Merge all data frames into one and make sure to retain the 'date' column
merge_all_data <- function(data_list) {
  full_data <- bind_rows(data_list)
  return(full_data)
}

```

```{r}
# Create combined data set
folder_path <- "NO1_generation_per_type"
data_list <- process_generation_data_folder(folder_path)
NO1_combined <- merge_all_data(data_list)
```

```{r}

NO1_daily_combined <- NO1_combined %>%
  as_tibble() %>%
  group_by(date) %>% 
  summarise(across(where(is.numeric), ~ round(mean(.), 1)), .groups = "drop") %>%
  select(where(~!all(is.na(.)))) %>%
  as_tsibble(index = date)
```

